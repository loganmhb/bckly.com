---
title: Some thoughts about Neuralink
---

Wait But Why essay: http://waitbutwhy.com/2017/04/neuralink.html

A certain part of my resistance to this idea is a kind of Puritan sense that good things must be worked for, I'm sure. But I also feel like brain-machine interfaces are playing with fire in a serious way and the WBW piece doesn't seem interested in that. Perhaps I'm a pessimist.

What was the experiment with rats and electrodes where the rats chose electrical brain stimulation over food? (Although there was a follow-up, if I recall correctly, where the experimenters found that rats in a healthy social environment made different choices, with clear political implications for humans.)

Aside from ethical or moral concerns, there are some more technical or ontological ones. I know very little about neuroscience so I'm not talking about that kind of technicality, but the portion of the essay about the bandwidth of thought and the possibility of direct communication of thoughts from one brain to another struck me as a simplistic view.

Speaking purely from a subjective, experiential point of view, thoughts are not a precise medium. They're nuanced but ambiguous. Aside from the kinds of thoughts that the essay describes as "multimedia" (communicating a picture or a sound, for example), I'm skeptical that it will be possible to transfer a more abstract thought from one brain to another. Partly this is because brains are plastic and it seems likely to me that my brain and another person's brain are different enough that we couldn't even think the same thoughts, but partly it's because of how imprecise and ambiguous thoughts are to begin with. I'm not confident that I could replicate a thought from one day to another. I often don't feel as if I fully understand my _own_ thinking until I've coerced ambiguous thoughts into more precise linguistic terms. 

[What is the role of language in thought?]

I think this passage on the dangers of brain-machine interfaces is telling:

> In the last item I was thinking about bad guys using hacking to
> steal information from my brain. But brain interfaces can also put
> information in. Meaning a clever hacker might be able to change your
> thoughts or your vote or your identity or make you want to do
> something terrible you normally wouldn’t ever consider. And you
> wouldn’t know it ever happened. You could feel strongly about voting
> for a candidate and a little part of you would wonder if someone
> manipulated your thoughts so you’d feel that way. The darkest
> possible scenario would be an ISIS-type organization actually
> influencing millions of people to join their cause by altering their
> thoughts.

That Urban is concerned about "an ISIS-type organization" rather than, say, an oppresive government looking for ways to pacify a resistant populace, betrays a poverty of thought here. Combine this with the US government's penchant for getting hardware-level backdoors installed into just about every kind of computer and you have a hard time arguing for a scenario where the NSA _can't_ read everyone's thoughts all of the time.
