---
title: Some thoughts about Neuralink
---

I recently read Tim Urban's Wait But Why [essay][wbw_neuralink] on Neuralink, Elon Musk's latest project. You should read it! It's very long (38,000 words, practically a novel) and Urban is something of a Musk fanboy, but in spite of that the piece is fascinating and thought-provoking. What follows are my kind of disorganized reactions to it.

The tl;dr is that Elon Musk is working on a company to create brain-machine interfaces that will essentially allow artificial intelligence and computers to become part of our brains, rather than simply an external aid. Cochlear implants are an example of a very basic brain-machine interface available today -- a microphone translates sound into electrodes that stimulate the cochlear nerve, which can restore hearing to the deaf. This is only the very beginning, of course; ultimately Musk's vision is that brain-machine interfaces that are orders of magnitude more complex and sophisticated will allow previously inconceivable forms of communication -- sharing what you are literally seeing with someone else directly brain-to-brain so that they _see exactly the same thing_, to use one of the easier-to-imagine examples Urban gives.

Given the potential this technology has to make sci-fi fantasies into daily realities, I can understand Urban's enthusiasm, but as I made my way through the essay I couldn't dispell a sense of discomfort and skepticism. A certain part of my resistance is a kind of Puritan sense that good things must be worked for, I'm sure, and I look forward to being proved wrong about that. But I also feel like brain-machine interfaces are playing with fire in a serious way and Urban doesn't seem very interested in that. Perhaps I'm a pessimist.

## Ethical problems

The first thought that came to mind were the experiments that James Olds and Peter Milner did in the 1950s where they implanted an electrode into the brains of rats such that the rats could press a lever to receive a pleasurable electrical stimulus. The rats preferred the electrical stimulus even to food, water, and sex.[^1] My brief internet research indicates that humans are similarly susceptible. I also learned about a disturbing study done in the 1970s in which researchers attempted to use brain stimulation to "cure" a man of homosexuality.[^2] I can't help but imagine ways in which more powerful brain interfaces could be abused further to enforce oppressive societal norms.

Urban does mention the dangers of brain-machine interfaces, but I think this passage is telling:

> In the last item I was thinking about bad guys using hacking to
> steal information from my brain. But brain interfaces can also put
> information in. Meaning a clever hacker might be able to change your
> thoughts or your vote or your identity or make you want to do
> something terrible you normally wouldn’t ever consider. And you
> wouldn’t know it ever happened. You could feel strongly about voting
> for a candidate and a little part of you would wonder if someone
> manipulated your thoughts so you’d feel that way. *The darkest
> possible scenario would be an ISIS-type organization actually
> influencing millions of people to join their cause by altering their
> thoughts.*

[emphasis added]

That Urban is concerned about "an ISIS-type organization" rather than, say, an oppresive government looking for ways to pacify a resistant populace, betrays a poverty of thought here. Combine this with the US government's penchant for dragnet surveillance and success in getting [hardware-level backdoors][backdoor] installed into just about every kind of computer and you have a hard time arguing for a scenario where the NSA _can't_ read everyone's thoughts all of the time.


## Other concerns

Aside from ethical or moral concerns, there are some more technical or ontological ones. I know very little about neuroscience so I'm not talking about that kind of technicality, but the portion of the essay about the bandwidth of thought and the possibility of direct communication of thoughts from one brain to another struck me as a simplistic view.

Speaking purely from a subjective, experiential point of view, thoughts are not a precise medium. They're nuanced but ambiguous. Aside from the kinds of thoughts that the essay describes as "multimedia" (communicating a picture or a sound, for example), I'm skeptical that it will be possible to transfer a more abstract thought from one brain to another. Partly this is because brains are plastic and it seems likely to me that my brain and another person's brain are different enough that we couldn't even think the same thoughts, but partly it's because of how imprecise and ambiguous thoughts are to begin with. I'm not confident that I could replicate a thought from one day to another. I often don't feel as if I fully understand my _own_ thinking until I've coerced ambiguous thoughts into more precise linguistic terms.

[What is the role of language in thought?]

Then there is the question of art. Urban wonders whether the radical new communicative capabilities of a brain-machine interface might allow more artists to fulfill their potential:

> How many symphonies could Mozart have written if he had been able to
> think the music in his head onto the page? How many Mozarts are out
> there right now who never learned how to play instruments well
> enough to get their talent out?

The possibilities are certainly interesting, but this line of reasoning makes a qualitative error about how art works, I think. Artistic mediums are more than obstacles to producing art. In fact their role as obstacle is crucial to their purpose. Art arises from a medium resisting a message, and a work of art is the record of an artist's struggle with that resistance. The resistance doesn't merely modulate the artistic expression -- it _creates_ the artistic expression. Mozart didn't have some sort of pristine musical ideas that fell through instruments and sheet music into their earthly, fallen form. Without the instruments and the sheet music there would be no Mozart. Instead there would be other forms, defined by other constraints.


[^counterpoint]: Counterpoint: lab rats have similarly been shown to prefer cocaine to food, but the [Rat Park][ratpark] experiment casts doubt over whether that is truly because of cocaine's addictive power or whether it can instead be blamed on the poor conditions the rats live in. That might be true of the electrode experiments, too.
[^study]: I found out about the study from this [HuffPo](http://www.huffingtonpost.com/david-j-linden/compass-pleasure_b_890342.html) article.

[wbw_neuralink]: http://waitbutwhy.com/2017/04/neuralink.html
[ratpark]: https://en.wikipedia.org/wiki/Rat_Park
[backdoor]: https://www.technologyreview.com/s/519661/nsas-own-hardware-backdoors-may-still-be-a-problem-from-hell/